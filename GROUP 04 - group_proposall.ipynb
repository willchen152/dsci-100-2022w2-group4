{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d767a7-511b-445f-9527-af2d587008bb",
   "metadata": {},
   "source": [
    "# <strong> Using age, blood pressure, cholestrol level, and heart rate to classify heart disease patients in Cleveland. </strong>\n",
    "\n",
    "\n",
    "### Group 04 - Arshia Singla, Naufal Prasojo, Henry Shi, William Chen\n",
    "\n",
    "\n",
    "Heart disease, also known as cardiovascular disease, is a broad term encompassing a variety of conditions affecting the heart (such as heart failure and pulmonary heart disease) and blood vessels (such as coronary artery disease and aortic aneurysm). \n",
    "\n",
    "It remains a leading cause of morbidity and mortality worldwide, accounting for a significant proportion of deaths each year. Understanding heart disease and its risk factors is essential due to its widespread prevalence and profound impact on public health. \n",
    "\n",
    "By exploring and analysing the dataset, we can identify patterns, trends, and correlations, which can inform evidence-based practices, and policies aimed at reducing the global issue of heart disease and improving patient outcomes. Furthermore, investigating the heart disease datasets can facilitate the development of predictive models, risk assessment tools, and personalized healthcare approaches. Overall, this exploration is crucial for enhancing our understanding of this complex condition and implementing effective strategies to prevent, diagnose, and manage it. \n",
    "\n",
    "The goal of this project is to use the risk factors of heart disease to classify patients based on the possibility to have a heart disease.\n",
    "\n",
    "The question that we will be trying to answer is: <strong> Is a new patient likely to have a heart disease based on their age, blood pressure, cholestrol level, and maximum heart rate? </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185978e1-2ff3-4e6c-927f-253f280c79c7",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff24f5e-722e-4a77-b9e8-0a21e19b283b",
   "metadata": {},
   "source": [
    "We will be using the Heart Disease dataset from the Cleveland database. It is a multivariate dataset. \n",
    "This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to date.  The \"goal\" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  \n",
    "   \n",
    "The names and social security numbers of the patients were recently removed from the database, replaced with dummy values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bfbd50-23b7-41c5-9eee-329c3d802bc0",
   "metadata": {},
   "source": [
    "### Preliminary exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ebf9f7-30a7-4555-868f-4239dec790b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.4     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.2.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.3\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.1.1     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.2.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.8     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Dig deeper into tidy modeling with R at \u001b[32mhttps://www.tmwr.org\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    " \n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(RColorBrewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9464ea23-3c90-4185-9630-44bbe46bee8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: 'data/processed.cleveland.data' does not exist in current working directory ('/home/jovyan/work/dsci-100-2023w2-group4').\n",
     "output_type": "error",
     "traceback": [
      "Error: 'data/processed.cleveland.data' does not exist in current working directory ('/home/jovyan/work/dsci-100-2023w2-group4').\nTraceback:\n",
      "1. read_csv(\"data/processed.cleveland.data\", col_names = c(\"age\", \n .     \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \n .     \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"), col_types = list(\"d\", \n .     \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"f\", \"f\", \n .     \"d\"))",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. vroom_(file, delim = delim %||% col_types$delim, col_names = col_names, \n .     col_types = col_types, id = id, skip = skip, col_select = col_select, \n .     name_repair = .name_repair, na = na, quote = quote, trim_ws = trim_ws, \n .     escape_double = escape_double, escape_backslash = escape_backslash, \n .     comment = comment, skip_empty_rows = skip_empty_rows, locale = locale, \n .     guess_max = guess_max, n_max = n_max, altrep = vroom_altrep(altrep), \n .     num_threads = num_threads, progress = progress)",
      "4. (function (path, write = FALSE) \n . {\n .     if (is.raw(path)) {\n .         return(rawConnection(path, \"rb\"))\n .     }\n .     if (!is.character(path)) {\n .         return(path)\n .     }\n .     if (is_url(path)) {\n .         if (requireNamespace(\"curl\", quietly = TRUE)) {\n .             con <- curl::curl(path)\n .         }\n .         else {\n .             inform(\"`curl` package not installed, falling back to using `url()`\")\n .             con <- url(path)\n .         }\n .         ext <- tolower(tools::file_ext(path))\n .         return(switch(ext, zip = , bz2 = , xz = {\n .             close(con)\n .             stop(\"Reading from remote `\", ext, \"` compressed files is not supported,\\n\", \n .                 \"  download the files locally first.\", call. = FALSE)\n .         }, gz = gzcon(con), con))\n .     }\n .     path <- enc2utf8(path)\n .     p <- split_path_ext(basename_utf8(path))\n .     if (write) {\n .         path <- normalizePath_utf8(path, mustWork = FALSE)\n .     }\n .     else {\n .         path <- check_path(path)\n .     }\n .     if (is_installed(\"archive\")) {\n .         formats <- archive_formats(p$extension)\n .         extension <- p$extension\n .         while (is.null(formats) && nzchar(extension)) {\n .             extension <- split_path_ext(extension)$extension\n .             formats <- archive_formats(extension)\n .         }\n .         if (!is.null(formats)) {\n .             p$extension <- extension\n .             if (write) {\n .                 if (is.null(formats[[1]])) {\n .                   return(archive::file_write(path, filter = formats[[2]]))\n .                 }\n .                 return(archive::archive_write(path, p$path, format = formats[[1]], \n .                   filter = formats[[2]]))\n .             }\n .             if (is.null(formats[[1]])) {\n .                 return(archive::file_read(path, filter = formats[[2]]))\n .             }\n .             return(archive::archive_read(path, format = formats[[1]], \n .                 filter = formats[[2]]))\n .         }\n .     }\n .     if (!write) {\n .         compression <- detect_compression(path)\n .     }\n .     else {\n .         compression <- NA\n .     }\n .     if (is.na(compression)) {\n .         compression <- tools::file_ext(path)\n .     }\n .     if (write && compression == \"zip\") {\n .         stop(\"Can only read from, not write to, .zip\", call. = FALSE)\n .     }\n .     switch(compression, gz = gzfile(path, \"\"), bz2 = bzfile(path, \n .         \"\"), xz = xzfile(path, \"\"), zip = zipfile(path, \"\"), \n .         if (!has_trailing_newline(path)) {\n .             file(path)\n .         } else {\n .             path\n .         })\n . })(\"data/processed.cleveland.data\")",
      "5. check_path(path)",
      "6. stop(\"'\", path, \"' does not exist\", if (!is_absolute_path(path)) {\n .     paste0(\" in current working directory ('\", getwd(), \"')\")\n . }, \".\", call. = FALSE)"
     ]
    }
   ],
   "source": [
    "set.seed(1)\n",
    "\n",
    "# reading the data, assigning column names and character types\n",
    "cleveland_data <- read_csv(\"data/processed.cleveland.data\",\n",
    "                           col_names = c(\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \n",
    "                                        \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"),\n",
    "                           col_types = list(\"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"f\" , \"f\", \"d\"))\n",
    "\n",
    "# cleaning (tidying) and wrangling data\n",
    "cleveland_data[ cleveland_data == \"?\" ] <- NA\n",
    "\n",
    "cleveland_tidy <- cleveland_data |>\n",
    "                   mutate(diagno = ifelse(is.na(num), NA, (num > 0))) |>\n",
    "                   mutate(sex = as_factor(sex), cp = as_factor(cp),\n",
    "                         fbs = as_factor(fbs), restecg = as_factor(restecg),\n",
    "                         exang = as_factor(exang), thal = as_factor(thal), \n",
    "                         ca = as_factor(ca), slope = as_factor(slope))\n",
    "\n",
    "# splitting the dataframe into testing and training datasets\n",
    "cleveland_split <- initial_split(cleveland_tidy, prop = 0.75, strata = num)\n",
    "\n",
    "cleveland_training <- training(cleveland_split)\n",
    "cleveland_testing <- testing(cleveland_split)\n",
    "\n",
    "head(cleveland_training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81169f-997c-4784-9c62-1ca98179c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizing to get minimum, maximum, and mean of each predictor variable + total number of rows per class\n",
    "cleveland_summary <- cleveland_training |>\n",
    "                     group_by(diagno) |> \n",
    "                     summarize(min_age = min(age), max_age = max(age), mean_age = mean(age), \n",
    "                               min_chol = min(chol), max_chol = max(chol), mean_chol = mean(chol),\n",
    "                               min_trestbps = min(trestbps), max_trestbps = max(trestbps), mean_trestbps = mean(trestbps),\n",
    "                               min_thalach = min(thalach), max_thalach = max(thalach), mean_thalach = mean(thalach),\n",
    "                               no_of_patients = n())\n",
    "\n",
    "cleveland_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eae38f-cbd0-43be-96c0-e1b680db9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the training data (cleveland_training)\n",
    "options(repr.plot.height = 7, repr.plot.width = 7)\n",
    "\n",
    "plot1 <- cleveland_training |>\n",
    "          ggplot(aes(x = age, y = thalach, color = diagno)) + \n",
    "                  geom_point() +\n",
    "                  labs(x = \"Age (years)\", y = \"Maximum heart rate achieved\", color = \"Diagnosis\") + \n",
    "                  theme(text = element_text(size = 20)) +\n",
    "                  scale_color_brewer(palette = \"Dark2\")\n",
    "\n",
    "plot2 <- cleveland_training |>\n",
    "          ggplot(aes(x = age, y = chol, color = diagno)) + \n",
    "                  geom_point() +\n",
    "                  labs(x = \"Age (years)\",\n",
    "                       y = \"Cholestrol level (mg/dl)\", color = \"Diagnosis\") + \n",
    "                  theme(text = element_text(size = 20)) +\n",
    "                  scale_color_brewer(palette = \"Dark2\")\n",
    "\n",
    "plot3 <- cleveland_training |>\n",
    "          ggplot(aes(x = thalach, y = chol, color = diagno)) + \n",
    "                  geom_point() +\n",
    "                  labs(x = \"Maximum heart rate achieved\",\n",
    "                       y = \"Cholestrol level (mg/dl)\", color = \"Diagnosis\") + \n",
    "                  theme(text = element_text(size = 20)) +\n",
    "                  scale_color_brewer(palette = \"Dark2\")\n",
    "\n",
    "plot4 <- cleveland_training |>\n",
    "          ggplot(aes(x = thalach, y = trestbps, color = diagno)) + \n",
    "                  geom_point() +\n",
    "                  labs(x = \"Maximum heart rate achieved\",\n",
    "                       y = \"Resting Blood pressure (mm Hg)\", color = \"Diagnosis\") + \n",
    "                  theme(text = element_text(size = 20)) +\n",
    "                  scale_color_brewer(palette = \"Dark2\")\n",
    "\n",
    "plot1\n",
    "plot2\n",
    "plot3\n",
    "plot4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd2290-c564-46af-9866-99ea0b7ed97d",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "We are using data from the file processed.cleveland.data from the heart disease database to predict the likeliness of a patient from Cleveland having heart disease. The columns that we are using are as follows:\n",
    "\n",
    "1.  <strong> age: </strong> age in years\n",
    "2.  <strong> sex: </strong> sex (1 = male; 0 = female)\n",
    "3.  <strong> cp: </strong> chest pain type\n",
    "    - Value 1: typical angina;\n",
    "    - Value 2: atypical angina;\n",
    "    - Value 3: non-anginal pain;\n",
    "    - Value 4: asymptomatic)\n",
    "4.  <strong> trestbps: </strong> resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5.  <strong> chol: </strong> serum cholestrol in mg/dl\n",
    "6.  <strong> fbs: </strong> (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "7.  <strong> restecg: </strong> resting electrocardiographic results \n",
    "    - Value 0: normal;\n",
    "    - Value 1: having ST-T wave abnormality;\n",
    "    - Value 2: showing probable or definite                                                                                    left ventricular hypertrophy                                                                                    by Estes' criteria\n",
    "8.  <strong> thalach: </strong> maximum heart rate achieved\n",
    "9.  <strong> exang: </strong> exercise induced angina (1 = yes; 0 = no)\n",
    "10. <strong> oldpeak: </strong> ST depression induced by exercise relative to rest \n",
    "11. <strong> slope: </strong> the slope of the peak exercise ST segment\n",
    "    - Value 1: upsloping;\n",
    "    - Value 2: flat;\n",
    "    - Value 3: downsloping\n",
    "12. <strong> ca: </strong> number of major vessels (0 - 3) colored by fluoroscopy\n",
    "13. <strong> thal: </strong> 3 = normal; 6 = fixed defect; 7 = reversible defect\n",
    "14. <strong> num: </strong> diagnosis of heart disease (1,2,3,4 = presence, 0 = no presence)\n",
    "\n",
    "\n",
    "Each column in the dataset has numeric values and it has 303 rows. The missing data is represented with the string \"?\".\n",
    "\n",
    "To clean (or tidy) the data, we changed all the \"?\" values to NA. Since, the <strong> num </strong> column uses integers to indicate the presence (1,2,3,4) or absence (0) of the heart disease in a patient, and we want to determine whether or not a patient has heart disease, we added a new boolean column <strong> diagno </strong> to represent the diagnosis as TRUE or FALSE. \n",
    "\n",
    "We then used the initial_split() function to split our tidied dataframe into 75% training data and 25% testing data while stratifying for <strong> diagno</strong>. However, for analysis, we only used the training set. \n",
    "\n",
    "We chose 4 predictor variables based on the risk factors of heart disease which are:\n",
    "\n",
    "- There are many risk factors for heart diseases, with <strong> age </strong>being the most important one (Francis DP et al., 2013).\n",
    "\n",
    "- High levels of LDL (\"bad\") <strong>cholestrol</strong> can accumulate in the walls of arteries, forming plaque which narrows the arteries and restricts blood flow to the heart muscle. This increases the risk of heart attack, and coronary artery disease. \n",
    "\n",
    "- Abnormalities in <strong>heart rate</strong> can indicate underlying cardiovascular issues and risks for individuals with heart disease. \n",
    "\n",
    "- <strong>High blood pressure</strong> (or hypertension), increases the risk of heart disease by damaging arteries, leading to stroke, aneurysms, etc. \n",
    "\n",
    "To summarize our data, we grouped the rows by <strong> diagno </strong> and then summarized each of the columns by doing minimum, maximum, and mean for each of our predictor variables <strong> age </strong>, <strong> chol </strong>, <strong> trestbps </strong>, and <strong> thalach </strong>. \n",
    "\n",
    "From this summarization, we noticed:\n",
    "\n",
    "- mean age, the mean cholestrol levels, and the mean resting blood pressure of the patients suffering with heart disease are higher.\n",
    "- on an average, the maximum heart rate achieved is lower for the patients with heart disease.\n",
    "\n",
    "To visualize these relationships, we generated some scatterplots of these variables against each other. This process helped us identify that the predictors we decided to use were indeed a good choice. When we plotted  <strong> thalach </strong> v/s  <strong> age </strong>, and coloured the points based on  <strong> diagno </strong>, we could see the clear distinction between the regions of TRUE diagnoses, FALSE diagnoses, and the regions where the points are overlapping. Similarly, we could see the distinct distributions when we plotted <strong> chol </strong> v/s <strong> age </strong>, <strong> chol </strong> v/s <strong> thalach </strong>, and <strong> trestbps </strong> v/s <strong> thalach </strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d308d-4a84-4ce9-b713-235a3f3ef637",
   "metadata": {},
   "source": [
    "### Expected outcomes and significance\n",
    "\n",
    "Based on the data analysization above, we expect to find that a patient with heart disease would be older and have high cholestrol levels, high blood pressure and low maximum heart rate. Further, we expect to find more intricate relationships between these risk factors causing heart disease.\n",
    "\n",
    "If a classification model was devised to make predictions and report a patient with heart disease, that would make it easier for the doctors to diagnose patients and the whole process would be a lot more efficient. Moreover, the patients would be able to get treated in the earlier stages of heart disease, increasing the possiblity of healing quickly and completely. \n",
    "\n",
    "Some future questions this could lead to are as follows: \n",
    "\n",
    "- What are the two primary risk factors that are most strongly associated with causing heart disease?\n",
    "- How can one mitigate the impact of a specific risk factor through preventive measures?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3fb5f-e4eb-4ffb-8097-ed13cfa27320",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "\n",
    "Janosi,Andras, Steinbrunn,William, Pfisterer,Matthias, and Detrano,Robert. (1988). Heart Disease. UCI Machine Learning Repository. https://doi.org/10.24432/C52P4X.\n",
    "\n",
    "Wikimedia Foundation. (2024a, February 15). Cardiovascular disease. Wikipedia. https://en.wikipedia.org/wiki/Cardiovascular_disease "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
